{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.dotenv import base_dir, data_dir\n",
    "from app.load_data import *\n",
    "from app.object_detection.cropROI import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save yolo models to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\yili0901/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-12-8 Python-3.11.6 torch-2.5.1+cpu CPU\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████| 14.1M/14.1M [00:03<00:00, 3.81MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to c:\\Users\\yili0901\\Downloads\\code\\identify_static_video_changes\\data/yolov5s_weights.pt\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21.5M/21.5M [00:05<00:00, 3.82MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to c:\\Users\\yili0901\\Downloads\\code\\identify_static_video_changes\\data/yolov8s_weights.pt\n"
     ]
    }
   ],
   "source": [
    "from app.object_detection.yolo import saveYOLOv5Model, saveYOLOv8Model\n",
    "\n",
    "saveYOLOv5Model(data_dir)\n",
    "saveYOLOv8Model(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\yili0901\\\\Downloads\\\\code\\\\identify_static_video_changes\\\\data\\\\ROIs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cropped_regions \u001b[38;5;241m=\u001b[39m \u001b[43mloadImagesList\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mROIs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m plotCrop(cropped_regions)\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Downloads\\code\\identify_static_video_changes\\app\\load_data\\__init__.py:71\u001b[0m, in \u001b[0;36mloadImagesList\u001b[1;34m(save_path)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadImagesList\u001b[39m(save_path):\n\u001b[0;32m     70\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     72\u001b[0m         imgs\u001b[38;5;241m.\u001b[39mappend(loadFrame( save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;66;03m# cv.imshow('img',img)\u001b[39;00m\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;66;03m# cv.waitKey(0)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;66;03m# cv.destroyAllWindows()\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\yili0901\\\\Downloads\\\\code\\\\identify_static_video_changes\\\\data\\\\ROIs'"
     ]
    }
   ],
   "source": [
    "cropped_regions = loadImagesList(save_path = f'{data_dir}\\\\ROIs')\n",
    "plotCrop(cropped_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yolo v5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully\n",
      "\n",
      "0: 640x640 1 person, 147.0ms\n",
      "1: 640x640 1 person, 147.0ms\n",
      "2: 640x640 1 person, 1 car, 147.0ms\n",
      "Speed: 3.7ms preprocess, 147.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from app.object_detection.yolo import loadYOLOv5Model, loadYOLOv8Model\n",
    "# model = loadYOLOv5Model(data_dir)\n",
    "model = loadYOLOv8Model(data_dir)\n",
    "\n",
    "\n",
    "# Example inference\n",
    "imgs = cropped_regions\n",
    "\n",
    "# results = model(imgs)  # Replace with your image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # results.save()  # Save the results\n",
    "# # results.print()  # Print the results\n",
    "\n",
    "# # AttributeError: 'list' object has no attribute 'save'\n",
    "\n",
    "# # Iterate through the results to save and print each one\n",
    "# for i, result in enumerate(results):\n",
    "#     # Save the result\n",
    "#     result.save(f'{i}')  # Specify save directory if needed\n",
    "#     # Print the result\n",
    "#     print(f\"Result for image {i + 1}:\")\n",
    "#     print(result)\n",
    "#     df = result.pandas().xyxy  # Convert to pandas DataFrame (bounding box format: xmin, ymin, xmax, ymax)\n",
    "#     print(f\"Results for image {i + 1}:\")\n",
    "#     print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x576 1 person, 147.8ms\n",
      "Speed: 5.0ms preprocess, 147.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 640x512 1 person, 116.3ms\n",
      "Speed: 2.2ms preprocess, 116.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 608x640 1 person, 137.4ms\n",
      "Speed: 2.0ms preprocess, 137.4ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'confidence': array(      0.895, dtype=float32),\n",
       "  'class': 0,\n",
       "  'name': 'person'},\n",
       " {'confidence': array(    0.88727, dtype=float32),\n",
       "  'class': 0,\n",
       "  'name': 'person'},\n",
       " {'confidence': array(    0.92863, dtype=float32),\n",
       "  'class': 0,\n",
       "  'name': 'person'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "all_results = inferenceYOLOv8Model(model)\n",
    "\n",
    "# # Convert the results list to a DataFrame\n",
    "# df = pd.DataFrame(all_results)\n",
    "\n",
    "# Print the DataFrame\n",
    "# print(df.head())\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[85, 78, 81], [82, 75, 78], [78, 71, 74], [7...</td>\n",
       "      <td>46.10493</td>\n",
       "      <td>8.442444</td>\n",
       "      <td>90.58266</td>\n",
       "      <td>99.769135</td>\n",
       "      <td>0.89499986</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[171, 172, 175], [172, 173, 176], [172, 173,...</td>\n",
       "      <td>49.422718</td>\n",
       "      <td>38.144257</td>\n",
       "      <td>96.686226</td>\n",
       "      <td>120.66614</td>\n",
       "      <td>0.8872712</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[40, 36, 30], [128, 124, 118], [148, 144, 13...</td>\n",
       "      <td>49.10714</td>\n",
       "      <td>16.532078</td>\n",
       "      <td>80.81857</td>\n",
       "      <td>91.0887</td>\n",
       "      <td>0.92862946</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image       xmin       ymin  \\\n",
       "0  [[[85, 78, 81], [82, 75, 78], [78, 71, 74], [7...   46.10493   8.442444   \n",
       "1  [[[171, 172, 175], [172, 173, 176], [172, 173,...  49.422718  38.144257   \n",
       "2  [[[40, 36, 30], [128, 124, 118], [148, 144, 13...   49.10714  16.532078   \n",
       "\n",
       "        xmax       ymax  confidence  class    name  \n",
       "0   90.58266  99.769135  0.89499986      0  person  \n",
       "1  96.686226  120.66614   0.8872712      0  person  \n",
       "2   80.81857    91.0887  0.92862946      0  person  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = cropped_regions\n",
    "\n",
    "# Inference\n",
    "model = loadYOLOv8Model(data_dir)\n",
    "results = model(imgs[0])\n",
    "results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "results.print()\n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # img1 predictions (pandas)\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# # Load the pretrained YOLO model\n",
    "# model = YOLO('yolov5s.pt')  # Using YOLOv5s for this example\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import shutil  # For saving the weights to a custom location\n",
    "\n",
    "# Define your desired path for saving the weights\n",
    "custom_weights_path = f\"{data_dir}/yolov5s_custom.pt\"\n",
    "\n",
    "# Load the pretrained YOLO model (this will download weights if not already available)\n",
    "model = YOLO('yolov5s.pt')\n",
    "\n",
    "# Save the model weights to the specified location\n",
    "original_weights_path = model.model.yaml.get('weights')  # Default weights path\n",
    "shutil.copy(original_weights_path, custom_weights_path)\n",
    "print(f\"Weights saved to {custom_weights_path}\")\n",
    "\n",
    "# Load the model using weights from the custom local address\n",
    "custom_model = YOLO(custom_weights_path)\n",
    "print(\"Custom model loaded successfully.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
